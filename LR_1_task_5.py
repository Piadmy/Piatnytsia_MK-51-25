# -*- coding: utf-8 -*-
"""ПР_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uRCNMFn3m5EXnrR2-yR6H6-BCUfSpKG7
"""

import numpy as np
from sklearn import preprocessing
input_data = np.array([[-1.3, 3.9, 6.2], [-4.9, 2.2, -4.3], [-2.2, 6.5, 4.1], [-5.2, -3.4, -5.2]])
# Бінаризація даних
data_binarized = preprocessing.Binarizer(threshold=2.2).transform(input_data)
print("\n Binarized data:\n", data_binarized)
# Виведення середнього значення та стандартного відхилення

print("\nBEFORE: ")
print("Mean =", input_data.mean(axis=0))
print("Std deviation =", input_data.std(axis=0))

# Исключение среднего
data_scaled = preprocessing.scale(input_data)
print("\nAFTER: ")
print("Mean =", data_scaled.mean(axis=0))
print("Std deviation =", data_scaled.std(axis=0))

# Масштабування MinМax
data_scaler_minmax = preprocessing.MinMaxScaler(feature_range=(0, 1))
data_scaled_minmax = data_scaler_minmax.fit_transform(input_data)
print("\nМin max scaled data:\n", data_scaled_minmax)

# Нормалізація даних
data_normalized_l1 = preprocessing.normalize(input_data, norm='l1')
data_normalized_l2 = preprocessing.normalize(input_data, norm='l2')
print("\nl1 normalized data:\n", data_normalized_l1)
print("\nl2 normalized data:\n", data_normalized_l2)

import numpy as np
from sklearn import preprocessing
# Надання позначок вхідних даних
Input_labels = ['red', 'black', 'red', 'green', 'black', 'yellow', 'white']
# Створення кодувальника та встановлення відповідності
# між мітками та числами
encoder = preprocessing.LabelEncoder()
encoder.fit(Input_labels)
# Виведення відображення
print("\nLabel mapping:")
for i, item in enumerate(encoder.classes_):
    print(item, '-->', i)
# перетворення міток за допомогою кодувальника
test_labels = ['green', 'red', 'black']
encoded_values = encoder.transform(test_labels )
print("\nLabels =", test_labels )
print("Encoded values =", list (encoded_values ) )

# Декодування набору чисел за допомогою декодера
encoded_values = [3, 0, 4, 1]
decoded_list = encoder.inverse_transform(encoded_values)
print("\nEncoded values =", encoded_values)
print("Decoded labels =", list (decoded_list ) )

import numpy as np
from sklearn import linear_model
import matplotlib.pyplot as plt

def visualize_classifier(classifier, X, y):
    # Define the minimum and maximum values for X and Y
    # that will be used in the mesh grid
    min_x, max_x = X[:, 0].min() - 1.0, X[:, 0].max() + 1.0
    min_y, max_y = X[:, 1].min() - 1.0, X[:, 1].max() + 1.0

    # Define the step size to use in plotting the mesh grid
    mesh_step_size = 0.01

    # Define the mesh grid of X and Y values
    x_vals, y_vals = np.meshgrid(
        np.arange(min_x, max_x, mesh_step_size),
        np.arange(min_y, max_y, mesh_step_size)
    )

    # Run the classifier on the mesh grid
    output = classifier.predict(np.c_[x_vals.ravel(), y_vals.ravel()])

    # Reshape the output array
    output = output.reshape(x_vals.shape)

    # Create a plot
    plt.figure()

    # Choose a color scheme for the plot
    plt.pcolormesh(x_vals, y_vals, output, cmap=plt.cm.gray)

    # Overlay the training points on the plot
    plt.scatter(X[:, 0], X[:, 1], c=y, s=75,
                edgecolors='black', linewidth=1, cmap=plt.cm.Paired)

    # Specify the boundaries of the plot
    plt.xlim(x_vals.min(), x_vals.max())
    plt.ylim(y_vals.min(), y_vals.max())

    # Specify the ticks on the X and Y axes
    plt.xticks(np.arange(int(X[:, 0].min() - 1), int(X[:, 0].max() + 1), 1.0))
    plt.yticks(np.arange(int(X[:, 1].min() - 1), int(X[:, 1].max() + 1), 1.0))

    plt.show()

# Визначення зразка вхідних даних
X = np.array([[3.1, 7.2], [4, 6.7], [2.9, 8], [5.1, 4.5],
              [6, 5], [5.6, 5], [3.3, 0.4],
              [3.9, 0.9], [2.8, 1],
              [0.5, 3.4], [1, 4], [0.6, 4.9]])
y = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3])
# Створення логістичного класифікатора
classifier = linear_model.LogisticRegression(solver='liblinear',C=1)
# Тренування класифікатора
classifier.fit(X, y)
visualize_classifier(classifier, X, y)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
def visualize_classifier(classifier, X, y):
    # Define the minimum and maximum values for X and Y
    # that will be used in the mesh grid
    min_x, max_x = X[:, 0].min() - 1.0, X[:, 0].max() + 1.0
    min_y, max_y = X[:, 1].min() - 1.0, X[:, 1].max() + 1.0

    # Define the step size to use in plotting the mesh grid
    mesh_step_size = 0.01

    # Define the mesh grid of X and Y values
    x_vals, y_vals = np.meshgrid(
        np.arange(min_x, max_x, mesh_step_size),
        np.arange(min_y, max_y, mesh_step_size)
    )

    # Run the classifier on the mesh grid
    output = classifier.predict(np.c_[x_vals.ravel(), y_vals.ravel()])

    # Reshape the output array
    output = output.reshape(x_vals.shape)

    # Create a plot
    plt.figure()

    # Choose a color scheme for the plot
    plt.pcolormesh(x_vals, y_vals, output, cmap=plt.cm.gray)

    # Overlay the training points on the plot
    plt.scatter(X[:, 0], X[:, 1], c=y, s=75,
                edgecolors='black', linewidth=1, cmap=plt.cm.Paired)

    # Specify the boundaries of the plot
    plt.xlim(x_vals.min(), x_vals.max())
    plt.ylim(y_vals.min(), y_vals.max())

    # Specify the ticks on the X and Y axes
    plt.xticks(np.arange(int(X[:, 0].min() - 1), int(X[:, 0].max() + 1), 1.0))
    plt.yticks(np.arange(int(X[:, 1].min() - 1), int(X[:, 1].max() + 1), 1.0))

    plt.show()
    # Вхідний файл, який містить дані

input_file = 'data_multivar_nb.txt'

# Завантаження даних із вхідного файлу
data = np.loadtxt(input_file, delimiter=',')
X, y = data[:, :-1], data[:, -1]
# Створення наївного байєсовського класифікатора
classifier = GaussianNB()
# Тренування класифікатора
classifier.fit(X, y)
# Прогнозування значень для тренувальних даних
y_pred = classifier.predict(X)
# Обчислення якості класифікатора
accuracy = 100.0 * (y == y_pred).sum() / X.shape[0]
print("Accuracy of Naive Bayes classifier =", round(accuracy, 2), "%")
# Візуалізація результатів роботи класифікатора
visualize_classifier(classifier, X, y)

# Розбивка даних на навчальний та тестовий набори
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)
classifier_new = GaussianNB()
classifier_new.fit(X_train, y_train)
y_test_pred = classifier_new.predict(X_test)

# Обчислення якості класифікатора
accuracy = 100.0 * (y_test == y_test_pred).sum() / X_test.shape[0]
print("Accuracy of the new classifier =", round(accuracy, 2),
"%")

# Візуалізація роботи класифікатора
visualize_classifier(classifier_new, X_test, y_test)

num_folds = 3
accuracy_values = cross_val_score(classifier,                          X, y, scoring='accuracy', cv=num_folds)
print("Accuracy: " + str(round(100 * accuracy_values.mean(), 2))
+ "%")
precision_values = cross_val_score(classifier,                X, y, scoring='precision_weighted', cv=num_folds)
print("Precision: " + str(round(100 * precision_values.mean(),
2)) + "%")

recall_values = cross_val_score(classifier,            X, y, scoring='recall_weighted', cv=num_folds)
print("Recall: " + str(round(100 * recall_values.mean(), 2)) +
"%")
f1_values = cross_val_score(classifier,
                      X, y, scoring='f1_weighted', cv=num_folds)
print("F1: " + str(round(100 * f1_values.mean(), 2)) + "%")

import numpy as np
import matplotlib.pyplot as plt
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
def visualize_classifier(classifier, X, y):
    # Define the minimum and maximum values for X and Y
    # that will be used in the mesh grid
    min_x, max_x = X[:, 0].min() - 1.0, X[:, 0].max() + 1.0
    min_y, max_y = X[:, 1].min() - 1.0, X[:, 1].max() + 1.0

    # Define the step size to use in plotting the mesh grid
    mesh_step_size = 0.01

    # Define the mesh grid of X and Y values
    x_vals, y_vals = np.meshgrid(
        np.arange(min_x, max_x, mesh_step_size),
        np.arange(min_y, max_y, mesh_step_size)
    )

    # Run the classifier on the mesh grid
    output = classifier.predict(np.c_[x_vals.ravel(), y_vals.ravel()])

    # Reshape the output array
    output = output.reshape(x_vals.shape)

    # Create a plot
    plt.figure()

    # Choose a color scheme for the plot
    plt.pcolormesh(x_vals, y_vals, output, cmap=plt.cm.gray)

    # Overlay the training points on the plot
    plt.scatter(X[:, 0], X[:, 1], c=y, s=75,
                edgecolors='black', linewidth=1, cmap=plt.cm.Paired)

    # Specify the boundaries of the plot
    plt.xlim(x_vals.min(), x_vals.max())
    plt.ylim(y_vals.min(), y_vals.max())

    # Specify the ticks on the X and Y axes
    plt.xticks(np.arange(int(X[:, 0].min() - 1), int(X[:, 0].max() + 1), 1.0))
    plt.yticks(np.arange(int(X[:, 1].min() - 1), int(X[:, 1].max() + 1), 1.0))

    plt.show()
    # Вхідний файл, який містить дані

input_file = 'data_multivar_nb.txt'

# Завантаження даних із вхідного файлу
data = np.loadtxt(input_file, delimiter=',')
X, y = data[:, :-1], data[:, -1]
# Створення наївного байєсовського класифікатора
classifier = GaussianNB()
# Тренування класифікатора
classifier.fit(X, y)
# Прогнозування значень для тренувальних даних
y_pred = classifier.predict(X)
# Обчислення якості класифікатора
accuracy = 100.0 * (y == y_pred).sum() / X.shape[0]
print("Accuracy of Naive Bayes classifier =", round(accuracy, 2), "%")
# Візуалізація результатів роботи класифікатора
visualize_classifier(classifier, X, y)

# Розбивка даних на навчальний та тестовий набори
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)
classifier_new = GaussianNB()
classifier_new.fit(X_train, y_train)
y_test_pred = classifier_new.predict(X_test)

# Обчислення якості класифікатора
accuracy = 100.0 * (y_test == y_test_pred).sum() / X_test.shape[0]
print("Accuracy of the new classifier =", round(accuracy, 2),
"%")

# Візуалізація роботи класифікатора
visualize_classifier(classifier_new, X_test, y_test)

num_folds = 3
accuracy_values = cross_val_score(classifier,                          X, y, scoring='accuracy', cv=num_folds)
print("Accuracy: " + str(round(100 * accuracy_values.mean(), 2))
+ "%")
precision_values = cross_val_score(classifier,                X, y, scoring='precision_weighted', cv=num_folds)
print("Precision: " + str(round(100 * precision_values.mean(),
2)) + "%")

recall_values = cross_val_score(classifier,            X, y, scoring='recall_weighted', cv=num_folds)
print("Recall: " + str(round(100 * recall_values.mean(), 2)) +
"%")
f1_values = cross_val_score(classifier,
                      X, y, scoring='f1_weighted', cv=num_folds)
print("F1: " + str(round(100 * f1_values.mean(), 2)) + "%")

X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.2, random_state=7)
classifier2 = GaussianNB()
classifier2.fit(X_train2, y_train2)
y_test_pred2 = classifier2.predict(X_test2)

# Обчислення точності
accuracy_test2 = 100.0 * (y_test2 == y_test_pred2).sum() / X_test2.shape[0]
print("Accuracy of the second run =", round(accuracy_test2, 2), "%")

# Візуалізація результатів на тестових даних
visualize_classifier(classifier2, X_test2, y_test2)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.metrics import (
    confusion_matrix,
    accuracy_score,
    recall_score,
    precision_score,
    f1_score,
    roc_curve,
    roc_auc_score
)

df = pd.read_csv('data.csv')
print(df.head())


thresh = 0.5
df['predicted_RF'] = (df.model_RF >= thresh).astype('int')
df['predicted_LR'] = (df.model_LR >= thresh).astype('int')
print(df.head())


def find_TP(y_true, y_pred):
    # true positives: y_true=1 and y_pred=1
    return int(np.sum((y_true == 1) & (y_pred == 1)))

def find_FN(y_true, y_pred):
    # false negatives: y_true=1 and y_pred=0
    return int(np.sum((y_true == 1) & (y_pred == 0)))

def find_FP(y_true, y_pred):
    # false positives: y_true=0 and y_pred=1
    return int(np.sum((y_true == 0) & (y_pred == 1)))

def find_TN(y_true, y_pred):
    # true negatives: y_true=0 and y_pred=0
    return int(np.sum((y_true == 0) & (y_pred == 0)))

y_true_rf = df.actual_label.values
y_pred_rf = df.predicted_RF.values
y_pred_lr = df.predicted_LR.values

print("Sklearn confusion_matrix (RF):")
print(confusion_matrix(y_true_rf, y_pred_rf))

print('TP:', find_TP(y_true_rf, y_pred_rf))
print('FN:', find_FN(y_true_rf, y_pred_rf))
print('FP:', find_FP(y_true_rf, y_pred_rf))
print('TN:', find_TN(y_true_rf, y_pred_rf))


def find_conf_matrix_values(y_true, y_pred):
    TP = find_TP(y_true, y_pred)
    FN = find_FN(y_true, y_pred)
    FP = find_FP(y_true, y_pred)
    TN = find_TN(y_true, y_pred)
    return TP, FN, FP, TN


def Piatnytsia_confusion_matrix(y_true, y_pred):
    TP, FN, FP, TN = find_conf_matrix_values(y_true, y_pred)
    return np.array([[TN, FP],
                     [FN, TP]])

assert np.array_equal(
    Piatnytsia_confusion_matrix(y_true_rf, y_pred_rf),
    confusion_matrix(y_true_rf, y_pred_rf)
), 'Piatnytsia_confusion_matrix() is not correct for RF'

assert np.array_equal(
    Piatnytsia_confusion_matrix(y_true_rf, y_pred_lr),
    confusion_matrix(y_true_rf, y_pred_lr)
), 'Piatnytsia_confusion_matrix() is not correct for LR'

print("Piatnytsia_confusion_matrix (RF):")
print(Piatnytsia_confusion_matrix(y_true_rf, y_pred_rf))


def Piatnytsia_accuracy_score(y_true, y_pred):
    TP, FN, FP, TN = find_conf_matrix_values(y_true, y_pred)
    return (TP + TN) / (TP + TN + FP + FN)

assert Piatnytsia_accuracy_score(y_true_rf, y_pred_rf) == accuracy_score(y_true_rf, y_pred_rf), \
    'Piatnytsia_accuracy_score failed on RF'
assert Piatnytsia_accuracy_score(y_true_rf, y_pred_lr) == accuracy_score(y_true_rf, y_pred_lr), \
    'Piatnytsia_accuracy_score failed on LR'

print('Accuracy RF: %.3f' % (Piatnytsia_accuracy_score(y_true_rf, y_pred_rf)))
print('Accuracy LR: %.3f' % (Piatnytsia_accuracy_score(y_true_rf, y_pred_lr)))

def Piatnytsia_recall_score(y_true, y_pred):
    TP, FN, FP, TN = find_conf_matrix_values(y_true, y_pred)
    denom = TP + FN
    return TP / denom if denom != 0 else 0.0

assert Piatnytsia_recall_score(y_true_rf, y_pred_rf) == recall_score(y_true_rf, y_pred_rf), \
    'Piatnytsia_recall_score failed on RF'
assert Piatnytsia_recall_score(y_true_rf, y_pred_lr) == recall_score(y_true_rf, y_pred_lr), \
    'Piatnytsia_recall_score failed on LR'

print('Recall RF: %.3f' % (Piatnytsia_recall_score(y_true_rf, y_pred_rf)))
print('Recall LR: %.3f' % (Piatnytsia_recall_score(y_true_rf, y_pred_lr)))


def Piatnytsia_precision_score(y_true, y_pred):
    TP, FN, FP, TN = find_conf_matrix_values(y_true, y_pred)
    denom = TP + FP
    return TP / denom if denom != 0 else 0.0

assert Piatnytsia_precision_score(y_true_rf, y_pred_rf) == precision_score(y_true_rf, y_pred_rf), \
    'Piatnytsia_precision_score failed on RF'
assert Piatnytsia_precision_score(y_true_rf, y_pred_lr) == precision_score(y_true_rf, y_pred_lr), \
    'Piatnytsia_precision_score failed on LR'

print('Precision RF: %.3f' % (Piatnytsia_precision_score(y_true_rf, y_pred_rf)))
print('Precision LR: %.3f' % (Piatnytsia_precision_score(y_true_rf, y_pred_lr)))


def Piatnytsia_f1_score(y_true, y_pred):
    r = Piatnytsia_recall_score(y_true, y_pred)
    p = Piatnytsia_precision_score(y_true, y_pred)
    denom = p + r
    return (2 * p * r / denom) if denom != 0 else 0.0

assert np.isclose(Piatnytsia_f1_score(y_true_rf, y_pred_rf), f1_score(y_true_rf, y_pred_rf)), \
    'Piatnytsia_f1_score failed on RF'
assert np.isclose(Piatnytsia_f1_score(y_true_rf, y_pred_lr), f1_score(y_true_rf, y_pred_lr)), \
    'Piatnytsia_f1_score failed on LR'

print('F1 RF: %.3f' % (Piatnytsia_f1_score(y_true_rf, y_pred_rf)))
print('F1 LR: %.3f' % (Piatnytsia_f1_score(y_true_rf, y_pred_lr)))


print('\nScores with threshold = 0.5 (RF)')
print('Accuracy RF: %.3f' % (Piatnytsia_accuracy_score(df.actual_label.values, df.predicted_RF.values)))
print('Recall RF: %.3f' % (Piatnytsia_recall_score(df.actual_label.values, df.predicted_RF.values)))
print('Precision RF: %.3f' % (Piatnytsia_precision_score(df.actual_label.values, df.predicted_RF.values)))
print('F1 RF: %.3f' % (Piatnytsia_f1_score(df.actual_label.values, df.predicted_RF.values)))

print('\nScores with threshold = 0.25 (RF)')
pred_rf_025 = (df.model_RF >= 0.25).astype('int').values
print('Accuracy RF: %.3f' % (Piatnytsia_accuracy_score(df.actual_label.values, pred_rf_025)))
print('Recall RF: %.3f' % (Piatnytsia_recall_score(df.actual_label.values, pred_rf_025)))
print('Precision RF: %.3f' % (Piatnytsia_precision_score(df.actual_label.values, pred_rf_025)))
print('F1 RF: %.3f' % (Piatnytsia_f1_score(df.actual_label.values, pred_rf_025)))


fpr_RF, tpr_RF, thresholds_RF = roc_curve(df.actual_label.values, df.model_RF.values)
fpr_LR, tpr_LR, thresholds_LR = roc_curve(df.actual_label.values, df.model_LR.values)


plt.figure()
plt.plot(fpr_RF, tpr_RF, 'r-', label='RF')
plt.plot(fpr_LR, tpr_LR, 'b-', label='LR')
plt.plot([0, 1], [0, 1], 'k-', label='random')
plt.plot([0, 0, 1, 1], [0, 1, 1, 1], 'g-', label='perfect')
plt.legend()
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.show()

auc_RF = roc_auc_score(df.actual_label.values, df.model_RF.values)
auc_LR = roc_auc_score(df.actual_label.values, df.model_LR.values)

print('AUC RF: %.3f' % auc_RF)
print('AUC LR: %.3f' % auc_LR)

plt.figure()
plt.plot(fpr_RF, tpr_RF, 'r-', label='RF AUC: %.3f' % auc_RF)
plt.plot(fpr_LR, tpr_LR, 'b-', label='LR AUC: %.3f' % auc_LR)
plt.plot([0, 1], [0, 1], 'k-', label='random')
plt.plot([0, 0, 1, 1], [0, 1, 1, 1], 'g-', label='perfect')
plt.legend()
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.show()